{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smartaces/deepseek_colab_quickstart/blob/main/DeepSeek_API_Multi_Turn_R1_Reasoning_Chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DeepSeek API QuickStart**"
      ],
      "metadata": {
        "id": "3AwhmvlPtCFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Notebook helps you experiment with DeepSeek's chat and R1 reasoning AI model.\n",
        "\n",
        "Full instructions on how to use this are provided below.\n",
        "\n",
        "**Connect with Me**\n",
        "\n",
        "If you like this notebook or in any way found it helpful, feel free to connect with me on LinkedIn here: https://www.linkedin.com/in/james-bentley-1b329214/"
      ],
      "metadata": {
        "id": "FHA-3g4qs80a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNk3hfyAtRNj"
      },
      "source": [
        "## **Installs**\n",
        "\n",
        "\n",
        "As per the documentation here: https://api-docs.deepseek.com/\n",
        "\n",
        "DeepSeek uses the same API structure as OpenAI\n",
        "\n",
        "There are just a couple of modifications, to get started you pip install OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai --quiet"
      ],
      "metadata": {
        "id": "ao1Rq7xbYJeH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ade61bef-05c1-4af6-9aff-b751da46a1a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/456.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m450.6/456.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.1/456.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **API Key Setup**\n",
        "\n",
        "You will need to sign up for a DeepSeek API key here: https://www.deepseek.com/\n",
        "\n",
        "Make sure you have set your DeepSeek API in Key in Colab secrets naming it: **DeepSeek_API**\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "llxCToQGuPt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setup and load your openai key\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve the DeepSeek key from the user\n",
        "DeepSeek_API = userdata.get('DeepSeek_API')"
      ],
      "metadata": {
        "id": "SWzIRQ4tYx6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Quick Test To Check Model Names**\n",
        "\n",
        "This should confirm your API connection is working by giving you a response of available models..."
      ],
      "metadata": {
        "id": "e73zuFQB0Cbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# for backward compatibility, you can still use `https://api.deepseek.com/v1` as `base_url`.\n",
        "client = OpenAI(api_key=DeepSeek_API, base_url=\"https://api.deepseek.com\")\n",
        "print(client.models.list())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gtw1SOKI0Ome",
        "outputId": "8ab01f6d-abc6-4ce5-f0cc-5adeaa3d0404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SyncPage[Model](data=[Model(id='deepseek-chat', created=None, object='model', owned_by='deepseek'), Model(id='deepseek-reasoner', created=None, object='model', owned_by='deepseek')], object='list')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DeepSeek Streaming R1 Reasoning Multi-Turn Chat**"
      ],
      "metadata": {
        "id": "MUUZIn0d8Ga6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a basic chat functionality that stores up to six rolling messages for you to chat with DeepSeek R1. This is a good way to experience the full size model, and also gives a base for you to start testing and building your own code."
      ],
      "metadata": {
        "id": "Ytbb2BswBR8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#some styling\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "wgRPb-oi928f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Initialize client\n",
        "client = OpenAI(\n",
        "    api_key=userdata.get('DeepSeek_API'),\n",
        "    base_url=\"https://api.deepseek.com\"\n",
        ")\n",
        "\n",
        "print(\"Chat with DeepSeek Reasoner started. Type 'quit' to exit.\")\n",
        "print(\"This chat will show both the reasoning process and final answer.\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# Initialize conversation history\n",
        "conversation_history = []\n",
        "\n",
        "def get_streaming_response(messages):\n",
        "    \"\"\"Get a streaming response from the model while maintaining conversation history\"\"\"\n",
        "    try:\n",
        "        # Get streaming response\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"deepseek-reasoner\",\n",
        "            messages=messages,\n",
        "            stream=True\n",
        "        )\n",
        "\n",
        "        # Initialize content collectors\n",
        "        reasoning_content = \"\"\n",
        "        final_content = \"\"\n",
        "        has_started_content = False\n",
        "        is_in_reasoning = True  # Track whether we're still in the reasoning phase\n",
        "\n",
        "        # Print streaming response with clear separation\n",
        "        print(\"\\nReasoning Process:\")\n",
        "\n",
        "        for chunk in response:\n",
        "            # Check for finish_reason\n",
        "            if hasattr(chunk.choices[0], 'finish_reason') and chunk.choices[0].finish_reason:\n",
        "                if is_in_reasoning:\n",
        "                    is_in_reasoning = False\n",
        "                    print(\"\\nFinal Answer:\")\n",
        "                continue\n",
        "\n",
        "            # Handle reasoning content\n",
        "            if hasattr(chunk.choices[0].delta, 'reasoning_content'):\n",
        "                new_text = chunk.choices[0].delta.reasoning_content\n",
        "                if new_text is not None:\n",
        "                    reasoning_content += new_text\n",
        "                    print(new_text, end='', flush=True)\n",
        "\n",
        "            # Handle final content\n",
        "            if hasattr(chunk.choices[0].delta, 'content'):\n",
        "                new_text = chunk.choices[0].delta.content\n",
        "                if new_text is not None:\n",
        "                    if not has_started_content:\n",
        "                        if is_in_reasoning:\n",
        "                            print(\"\\n\\nFinal Answer:\\n\")\n",
        "                            is_in_reasoning = False\n",
        "                        has_started_content = True\n",
        "                    final_content += new_text\n",
        "                    print(new_text, end='', flush=True)\n",
        "\n",
        "        # Ensure we have both parts\n",
        "        if not final_content.strip():\n",
        "            # Try a non-streaming request to get the content\n",
        "            non_stream_response = client.chat.completions.create(\n",
        "                model=\"deepseek-reasoner\",\n",
        "                messages=messages,\n",
        "                stream=False\n",
        "            )\n",
        "            final_content = non_stream_response.choices[0].message.content\n",
        "            if final_content and not has_started_content:\n",
        "                print(\"\\n\\nFinal Answer:\")\n",
        "                print(final_content)\n",
        "\n",
        "        return reasoning_content.strip(), final_content.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError occurred: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "while True:\n",
        "    # Get user input\n",
        "    user_input = input(\"\\nYou: \")\n",
        "\n",
        "    if user_input.lower() in ['quit', 'exit', 'q']:\n",
        "        print(\"\\nChat ended.\")\n",
        "        break\n",
        "\n",
        "    try:\n",
        "        # Add user's message to history\n",
        "        conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        # Create message array with history\n",
        "        current_messages = conversation_history[-6:]  # Keep last 6 messages (3 exchanges)\n",
        "\n",
        "        # Get response\n",
        "        print(\"\\nDeepSeek is thinking...\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        reasoning, answer = get_streaming_response(current_messages)\n",
        "\n",
        "        if reasoning is not None and answer is not None:\n",
        "            # Add assistant's response to history (only the final answer, not reasoning)\n",
        "            conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
        "        else:\n",
        "            print(\"\\nFailed to get a response. Clearing conversation history and starting fresh.\")\n",
        "            conversation_history = []\n",
        "\n",
        "        print(\"\\n\" + \"-\" * 70)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError occurred: {str(e)}\")\n",
        "        print(\"Clearing conversation history and starting fresh.\")\n",
        "        conversation_history = []\n",
        "        print(\"-\" * 70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PewgqVHS8LeV",
        "outputId": "dcb70c58-bb98-4a9a-b3b6-4bd67c875c2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chat with DeepSeek Reasoner started. Type 'quit' to exit.\n",
            "This chat will show both the reasoning process and final answer.\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "You: hello\n",
            "\n",
            "DeepSeek is thinking...\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Reasoning Process:\n",
            "Okay, the user just said \"hello\". I need to respond in a friendly and welcoming manner.\n",
            "\n",
            "First, I should greet them back. Maybe \"Hello! How can I assist you today?\" That sounds good.\n",
            "\n",
            "Wait, I should check if there's any specific context or previous messages. The history shows this is the first message, so no prior context. Just a simple hello.\n",
            "\n",
            "Make sure the response is open-ended to encourage them to ask for help. Avoid being too robotic. Keep it natural.\n",
            "\n",
            "Maybe add a smiley emoji to make it more friendly. But the example response didn't use one. Hmm, perhaps better to stick without it unless the user does first.\n",
            "\n",
            "Alright, go with \"Hello! How can I assist you today?\" That's clear and inviting.\n",
            "\n",
            "Final Answer:\n",
            "\n",
            "Hello! How can I assist you today?\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "You: how many r's in strrrrrrrrorbrry\n",
            "\n",
            "DeepSeek is thinking...\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Reasoning Process:\n",
            "Okay, let's figure out how many times the letter 'r' appears in the string \"strrrrrrrrorbrry\". The user is asking for the count of 'r's here.\n",
            "\n",
            "First, I'll start by writing down the string to visualize it better: s t r r r r r r r r o r b r r y. Wait, let me make sure I got the exact letters right. The user wrote \"strrrrrrrrorbrry\". Let me break it down letter by letter.\n",
            "\n",
            "Starting with 's', then 't', followed by a bunch of 'r's. Let me count them step by step. After 't', the next letters are 'r's. Let's see:\n",
            "\n",
            "s - 1\n",
            "t - 2\n",
            "r - 3\n",
            "r - 4\n",
            "r -5\n",
            "r -6\n",
            "r -7\n",
            "r -8\n",
            "r -9\n",
            "r -10 (Wait, how many 'r's are there after 't'? The user wrote \"strrrrrrrrorbrry\". So after 'st', there's a series of 'r's. Let me count them: s t r r r r r r r r o r b r r y. Let me separate each character:\n",
            "\n",
            "1. s\n",
            "2. t\n",
            "3. r\n",
            "4. r\n",
            "5. r\n",
            "6. r\n",
            "7. r\n",
            "8. r\n",
            "9. r\n",
            "10. r\n",
            "11. o\n",
            "12. r\n",
            "13. b\n",
            "14. r\n",
            "15. r\n",
            "16. y\n",
            "\n",
            "Wait, but the original string is \"strrrrrrrrorbrry\". Let's parse it again:\n",
            "\n",
            "s, t, then 8 r's (since \"rrrrrrrr\" is 8 r's), then o, r, b, r, r, y. Let me verify:\n",
            "\n",
            "Breaking down \"strrrrrrrrorbrry\":\n",
            "\n",
            "- s (1)\n",
            "- t (2)\n",
            "- r (3)\n",
            "- r (4)\n",
            "- r (5)\n",
            "- r (6)\n",
            "- r (7)\n",
            "- r (8)\n",
            "- r (9)\n",
            "- r (10)\n",
            "Wait, maybe I miscounted the number of 'r's in the \"rrrrrrrr\" part. Let's see: the part after \"st\" is \"rrrrrrrr\", which is 8 r's. Then \"o\", \"r\", \"b\", \"r\", \"r\", \"y\". So:\n",
            "\n",
            "s (1)\n",
            "t (2)\n",
            "r (3)\n",
            "r (4)\n",
            "r (5)\n",
            "r (6)\n",
            "r (7)\n",
            "r (8)\n",
            "r (9)\n",
            "r (10)\n",
            "o (11)\n",
            "r (12)\n",
            "b (13)\n",
            "r (14)\n",
            "r (15)\n",
            "y (16)\n",
            "\n",
            "So total letters: 16. Now count the 'r's. From positions 3 to 10: that's 8 r's (positions 3-10 inclusive is 8 letters). Then position 12 is an r, position 14 and 15 are r's. So 8 +1 +2 = 11? Wait, 8 (from the initial r's) + 1 (after o) + 2 (after b) = 11. Let me check again:\n",
            "\n",
            "Looking at the original string: \"strrrrrrrrorbrry\"\n",
            "\n",
            "Breaking it down:\n",
            "\n",
            "s t r r r r r r r r o r b r r y\n",
            "\n",
            "So after s and t, there's 8 r's (from the \"rrrrrrrr\"), then o, then r, then b, then two r's, then y. So that's 8 +1 +2 = 11 r's total. Wait, but when I count the letters in the breakdown earlier, positions 3-10 (8 r's), then 12 (r), 14 (r), 15 (r). So that's 8 +1 +2 = 11. But wait position 15 is the second r after b. So positions 14 and 15 are two r's. So total r's: 8 +1 +2 = 11.\n",
            "\n",
            "Alternatively, maybe I made a mistake in counting the initial r's. Let me check the original string again: \"strrrrrrrrorbrry\"\n",
            "\n",
            "After \"st\", the next part is \"rrrrrrrr\" which is 8 r's. Then \"o\", \"r\", \"b\", \"rr\", \"y\". So the \"rr\" after b is two more. So total r's: 8 +1 +2 = 11.\n",
            "\n",
            "Yes, that's correct. So the answer should be 11.\n",
            "\n",
            "Final Answer:\n",
            "\n",
            "To determine how many times the letter **'r'** appears in the string **\"strrrrrrrrorbrry\"**, let's break it down:\n",
            "\n",
            "1. **s t**  \n",
            "   (Start with \"s\" and \"t\", no 'r's here.)\n",
            "\n",
            "2. **r r r r r r r r**  \n",
            "   (8 consecutive 'r's after \"st\".)\n",
            "\n",
            "3. **o r**  \n",
            "   (1 'r' after \"o\".)\n",
            "\n",
            "4. **b r r**  \n",
            "   (2 'r's after \"b\".)\n",
            "\n",
            "5. **y**  \n",
            "   (No 'r' at the end.)\n",
            "\n",
            "**Total 'r's:**  \n",
            "8 (from step 2) + 1 (from step 3) + 2 (from step 4) = **11**.\n",
            "\n",
            "**Answer:** There are **11** letter 'r's in the string.\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-ef4e5c708124>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# Get user input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nYou: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'quit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DeepSeek Non-Reasoning Multi-Turn Chat**\n",
        "\n",
        "Below is the code to run a simple mult-chat conversation with the DeepSeek chat model, note that this is not the R1 reasoning model, it is (as of 27/01/2025) running from their V3 model, which is not a reasoning model."
      ],
      "metadata": {
        "id": "eBMpXDO6mHzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Initialize client\n",
        "client = OpenAI(\n",
        "    api_key=userdata.get('DeepSeek_API'),\n",
        "    base_url=\"https://api.deepseek.com\"\n",
        ")\n",
        "\n",
        "# Initialize conversation with system message\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"}\n",
        "]\n",
        "\n",
        "print(\"Chat started. Type 'quit' to exit.\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"\\nYou: \")\n",
        "\n",
        "    if user_input.lower() in ['quit', 'exit', 'q']:\n",
        "        print(\"\\nChat ended.\")\n",
        "        break\n",
        "\n",
        "    # Add user message to conversation\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Get response\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"deepseek-chat\",\n",
        "        messages=messages,\n",
        "        stream=False\n",
        "    )\n",
        "\n",
        "    # Add assistant's response to conversation history\n",
        "    assistant_message = response.choices[0].message\n",
        "    messages.append(assistant_message)\n",
        "\n",
        "    # Print assistant's response\n",
        "    print(\"\\nAssistant:\", assistant_message.content)\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "YBQdhgh3lWlX",
        "outputId": "eb2f5ca5-e989-49a4-9cfe-dbe19cd7c02e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chat started. Type 'quit' to exit.\n",
            "--------------------------------------------------\n",
            "\n",
            "You: hello\n",
            "\n",
            "Assistant: Hello! How can I assist you today? 😊\n",
            "--------------------------------------------------\n",
            "\n",
            "You: whats gwanin\n",
            "\n",
            "Assistant: \"Wagwan\" is a casual greeting in Jamaican Patois, short for \"What's going on?\" or \"What's happening?\" It's a friendly way to ask how someone is doing or what's up. So, wagwan with you? 😊\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-53916cade244>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nYou: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'quit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}